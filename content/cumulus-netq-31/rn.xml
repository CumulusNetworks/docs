<tables>
<table name="Open Issues in 3.1.0">
<tr>
<th> Issue ID </th>
<th> Description </th>
<th> Affects </th>
<th> Fixed </th>
</tr>
<tr>
<td>2555854</td>
<td>NetQ Agent: If a NetQ Agent is downgraded to the 3.0.0 version from any higher release, the default commands file present in the _/etc/netq/commands/_ also needs to be updated to prevent the NetQ Agent from becoming rotten.</td>
<td>3.0.0-3.3.1</td>
<td></td>
</tr>
<tr>
<td>2553453</td>
<td>The {{netqd}} daemon logs a traceback to _/var/log/netqd.log_ when the OPTA server is unreachable and {{netq show}} commands are run.</td>
<td>3.1.0-3.3.1</td>
<td></td>
</tr>
<tr>
<td>2551790</td>
<td>CLI: Upgrade to NetQ 3.1.0 using the CLI fails due to an authentication issue. To work around this issue, run the {{netq bootstrap master upgrade}} command as usual, then use the Admin UI to complete the upgrade at _https://&lt;netq-appl-vm-hostname-or-ipaddr&gt;:8443_.</td>
<td>3.1.0-3.1.1</td>
<td>3.2.0-3.3.1</td>
</tr>
<tr>
<td>2551641</td>
<td>Infra: NetQ VM installation fails if the designated disk size is greater than 2TB. To work around this issue, specify the disk for cloud deployments to be between 256GB and 2TB SSD, and for on-premises deployments to be between 32 GB and 2TB.</td>
<td>2.4.0-3.1.1</td>
<td>3.2.0-3.3.1</td>
</tr>
<tr>
<td>2551569</td>
<td>CLI: When a proxy server is configured for NetQ Cloud access and lifecycle management (LCM) is enabled, the associated LCM CLI commands fail due to incorrect port specification. To work around this issue, configure the NetQ Collector to connect directly to NetQ Cloud without a proxy.</td>
<td>3.1.0-3.1.1</td>
<td>3.2.0-3.3.1</td>
</tr>
<tr>
<td>2551545</td>
<td>Infra: Rarely, after a node is restarted, Kubernetes pods do not synchronize properly and the output of {{netq show opta-health}} shows failures. Node operation is not functionally impacted. You can safely remove the failures by running {{kubectl get pods | grep MatchNodeSelector | cut \-f1 \-d' ' | xargs kubectl delete pod}}. To work around the issue, do not label nodes using the API. Instead label nodes through local configuration using {{kubelet flag "--node-labels"}}.</td>
<td>3.1.0-3.3.1</td>
<td></td>
</tr>
<tr>
<td>2549649</td>
<td>NetQ UI: Warnings might appear during the post-upgrade phase for a Cumulus Linux switch upgrade job. They are caused by services that have not yet been restored by the time the job is complete. Cumulus Networks recommend waiting five minutes, creating a network snapshot, then comparing that to the pre-upgrade snapshot. If the comparison shows no differences for the services, the warnings can be ignored. If there are differences, then troubleshooting the relevant service(s) is recommended.</td>
<td>3.0.0-3.3.1</td>
<td></td>
</tr>
<tr>
<td>2549344</td>
<td>UI: The lifecycle management feature does not present general alarm or info events; however, errors related to the upgrade process are reported within the NetQ UI.</td>
<td>3.0.0-3.1.1</td>
<td>3.2.0-3.3.1</td>
</tr>
<tr>
<td>2549319</td>
<td>NetQ UI: The legend and segment colors on Switches and Upgrade History card graphs sometimes do not match. These cards appear on the lifecycle management dashboard (Manage Switch Assets view). Hover over graph to view the correct values.</td>
<td>3.0.0-3.3.1</td>
<td></td>
</tr>
<tr>
<td>2549246</td>
<td>NetQ UI: Snapshot comparison cards may not render correctly after navigating away from a workbench and then returning to it. If you are viewing the Snapshot comparison card(s) on a custom workbench, refresh the page to reload the data. If you are viewing it on the Cumulus Default workbench, after refreshing the page you must recreate the comparison(s).</td>
<td>2.4.0-3.2.1</td>
<td>3.3.0-3.3.1</td>
</tr>
<tr>
<td>2543867</td>
<td>NetQ UI: If either the hostname or the ASN of a BGP peer is invalid, the full screen BGP Service card does not provide the ability to open cards for a selected BGP session.</td>
<td>2.3.0-2.4.1, 3.0.0-3.3.1</td>
<td></td>
</tr>
</table>
<table name="Fixed issues in 3.1.0">
<tr>
<th> Issue ID </th>
<th> Description </th>
<th> Affects </th>
</tr>
<tr>
<td>2549842</td>
<td>Switch upgrade of Cumulus Linux in the lifecycle management feature fails when attempted by a user with a standard or sudo user role and custom password credentials. To work around this issue, upgrades should be performed by users with root or sudo user role and an SSH key. Optionally, upgrade using a root user role with custom password. </td>
<td>3.0.0-3.0.1</td>
</tr>
<tr>
<td>2549787</td>
<td>When upgrading to NetQ 3.0.0, if you are using NetQ Agent 2.3.1 or earlier and have MLAG configured, the MLAG service becomes unresponsive. To resolve this issue, upgrade your NetQ Agents to version 3.0.0.</td>
<td>3.0.0-3.0.1</td>
</tr>
<tr>
<td>2549721</td>
<td>When installing NetQ on switches running in Cumulus Linux 3.7.x  with management VRF configured, the CLI and Agent server are configured as follows:
&lt;pre&gt;
netq config add cli server &lt;ipaddr&gt; vrf mgmt
netq config restart cli

netq config add agent server &lt;ipaddr&gt; vrf mgmt
netq config restart agent
&lt;/pre&gt;
This results in {{netqd}} running in both default and management VRF and the NetQ Agent running in default VRF. In this scenario, the NetQ Agent status is not reported correctly to the management VRF. To workaround this issue: 


If you have management VRF configured, run the following commands:
&lt;pre&gt;
systemctl stop netqd.service
systemctl disable netqd.service
systemctl enable netqd@mgmt.service
systemctl restart netqd@mgmt.service
&lt;/pre&gt;
If you have default VRF configured, run the following commands:
&lt;pre&gt;
systemctl stop netqd@mgmt.service
systemctl disable netqd@mgmt.service
systemctl enable netqd.service
systemctl restart netqd.service
&lt;/pre&gt;
</td>
<td>3.0.0-3.0.1</td>
</tr>
<tr>
<td>2549704</td>
<td>When multiple premises are deployed and Cumulus Linux upgrades have been performed on switches using the lifecycle management feature, the Upgrade History card displays history for all premises rather than only those for the selected premises.</td>
<td>3.0.0-3.0.1</td>
</tr>
<tr>
<td>2549682</td>
<td>Performing an upgrade using the lifecycle management feature fails intermittently when SSH key switch access authorization is used. To work around this issue, use basic authentication or retry an upgrade job that uses SSH key authorization.</td>
<td>3.0.0-3.0.1</td>
</tr>
<tr>
<td>2547642</td>
<td>Admin UI: If the Master Installation phase fails during NetQ installation, refreshing the page causes the error log to be lost. On failure, download the error log, then run {{netq bootstrap reset}} followed by {{netq bootstrap master interface}} on the node before restarting the installation process.</td>
<td>2.4.1-3.0.1</td>
</tr>
</table>
</tables>