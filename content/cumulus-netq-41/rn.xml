<tables>
<table name="Open Issues in 4.1.1">
<tr>
<th> Issue ID </th>
<th> Description </th>
<th> Affects </th>
<th> Fixed </th>
</tr>
<tr>
<td>3085064</td>
<td>When you attempt to install NetQ on a device using LCM and configure the incorrect VRF, the installation will be reflected as successful but the switch will not be present in the inventory in the LCM UI.</td>
<td>4.1.0-4.3.0</td>
<td>4.4.0-4.9.0</td>
</tr>
<tr>
<td>3015875</td>
<td>NetQ trace might report incomplete route information when there are multiple default routes in a VRF in the path between the source and destination.</td>
<td>4.1.0-4.4.1</td>
<td>4.5.0-4.9.0</td>
</tr>
<tr>
<td>3011307</td>
<td>NetQ Agent: The NetQ Agent fails to start in Cumulus Linux on switches with ARM CPUs. The log files show the following message:


systemd: netq-agent.service: Main process exited, code=exited, status=1/FAILURE
</td>
<td>4.1.1</td>
<td>4.2.0-4.9.0</td>
</tr>
<tr>
<td>2896825</td>
<td>WJH monitoring fails to start with netq-agent on Cumulus Linux 5.0. To work around this issue, reinstall the netq-agent package and configure the netq agent to start monitoring:


1. Add the gpg key for the repository:

{{wget -qO - https://apps3.cumulusnetworks.com/setup/cumulus-apps-deb.pubkey | sudo apt-key add -}}


2. Add the repository to {{/etc/apt/sources.list}}:

{{echo 'deb https://apps3.cumulusnetworks.com/repos/deb CumulusLinux-4 netq-latest' | sudo tee -a /etc/apt/sources.list}}


3. Reinstall the netq-agent package:

{{sudo apt-get update &amp;&amp; sudo apt-get install --reinstall netq-agent}}</td>
<td>4.1.0-4.1.1</td>
<td>4.2.0-4.9.0</td>
</tr>
<tr>
<td>2885440</td>
<td>After upgrading to NetQ 4.1.0, validation checks might show intermittent errors that are not valid while the validation application processess pending messages after upgrade. This condition will clear once all messages are processed.</td>
<td>4.1.0-4.1.1</td>
<td>4.2.0-4.9.0</td>
</tr>
<tr>
<td>2843640</td>
<td>In NetQ clustered environments, the network snapshot feature may fail.</td>
<td>4.0.0-4.1.1</td>
<td>4.2.0-4.9.0</td>
</tr>
<tr>
<td>2817749</td>
<td>If you configure an event suppression rule with {{is_active false}}, the event will no longer be displayed with the {{netq show events-config}} command.</td>
<td>4.0.1-4.2.0</td>
<td>4.3.0-4.9.0</td>
</tr>
<tr>
<td>2815596</td>
<td>The NetQ Cloud VM for KVM hypervisors installer and opta-check fail because the minimum disk requirements do not meet the default image settings. To work around this issue, increase the disk space from 32GB to 64GB before you run the {{netq bootstrap}} command.


1. Check the size of the existing hard disk in the VM to confirm it is 32 GB. In this example, the number of 1 MB blocks is 31583, or 32 GB.

	cumulus@netq-401-cloud:~$ df -hm /
	Filesystem     1M-blocks  Used Available Use% Mounted on
	/dev/vda1          31583  1192     30375   4% /

2. Shutdown the VM.

3. Check the size of the existing disk on the server hosting the VM to confirm it is 32 GB. In this example, the size appears in the virtual size field:


	root@server:/var/lib/libvirt/images# qemu-img info netq-4.0.1-ubuntu-18.04-tscloud-qemu.qcow2
	image: netq-4.0.1-ubuntu-18.04-tscloud-qemu.qcow2
	file format: qcow2
	virtual size: 32G (34359738368 bytes)
	disk size: 1.3G
	cluster_size: 65536
	Format specific information:
	    compat: 1.1
	    lazy refcounts: false
	    refcount bits: 16
	    corrupt: false

4. Add 32 GB to the image:

	root@server:/var/lib/libvirt/images# qemu-img resize netq-4.0.1-ubuntu-18.04-tscloud-qemu.qcow2 +32G
	Image resized.

5. Verify the change.

	root@server:/var/lib/libvirt/images# qemu-img info netq-4.0.1-ubuntu-18.04-tscloud-qemu.qcow2
	image: netq-3.1.0-ubuntu-18.04-tscloud-qemu.qcow2
	file format: qcow2
	virtual size: 64G (68719476736 bytes)
	disk size: 1.3G
	cluster_size: 65536
	Format specific information:
	    compat: 1.1
	    lazy refcounts: false
	    refcount bits: 16
	    corrupt: false

6. Start the VM and log back in.

7. Run the following commands on the partition, referencing the filesystem /dev/vda1 obtained in step 1:


	cumulus@netq-401-cloud:~$ sudo growpart /dev/vda 1
	CHANGED: partition=1 start=227328 old: size=66881503 end=67108831 new: size=133990367,end=134217695

	cumulus@netq-401-cloud:~$ sudo resize2fs /dev/vda1
	resize2fs 1.44.1 (24-Mar-2018)
	Filesystem at /dev/vda1 is mounted on /; on-line resizing required
	old_desc_blocks = 4, new_desc_blocks = 8
	The filesystem on /dev/vda1 is now 16748795 (4k) blocks long.

8. Verify the disk is now configured with 64 GB. In this example, the number of 1 MB blocks is now 63341, or 64 GB:

	cumulus@netq-401-cloud:~$ df -hm /
	Filesystem     1M-blocks  Used Available Use% Mounted on
	/dev/vda1          63341  1193     62132   2% /</td>
<td>4.0.1-4.1.1</td>
<td>4.2.0-4.9.0</td>
</tr>
<tr>
<td>2711101</td>
<td>When RoCE (RDMA over Converged Ethernet) data collection is enabled in Cumulus Linux 4.3.z and 4.4.z, you can experience high dual uplink convergence times.
To work around this issue, disable RoCE monitoring:

1. Edit &apos;/etc/netq/commands/cl4-netq-commands.yml&apos; and comment out the following lines:
        #- period: "60"
        #  key: "roce"
        #  isactive: true
        #  command: "/usr/lib/cumulus/mlxcmd --json roce counters"
        #  parser: "local"

2. Delete the &apos;/var/run/netq/netq_commands.yml&apos; file:
        $ sudo rm /var/run/netq/netq_commands.yml

3. Restart the NetQ agent:
       $ netq config agent restart</td>
<td>4.0.0-4.1.1</td>
<td>4.2.0-4.9.0</td>
</tr>
</table>
<table name="Fixed Issues in 4.1.1">
<tr>
<th> Issue ID </th>
<th> Description </th>
<th> Affects </th>
</tr>
<tr>
<td>2921628</td>
<td>CVE-2021-45046: It was found that the fix to address CVE-2021-44228 in Apache Log4j 2.15.0 was incomplete in certain non-default configurations.

CVE-2021-45105: Apache Log4j2 versions 2.0-alpha1 through 2.16.0 (excluding 2.12.3 and 2.3.1) did not protect from uncontrolled recursion from self-referential lookups. </td>
<td></td>
</tr>
</table>
<table name="Open Issues in 4.1.0">
<tr>
<th> Issue ID </th>
<th> Description </th>
<th> Affects </th>
<th> Fixed </th>
</tr>
<tr>
<td>3085064</td>
<td>When you attempt to install NetQ on a device using LCM and configure the incorrect VRF, the installation will be reflected as successful but the switch will not be present in the inventory in the LCM UI.</td>
<td>4.1.0-4.3.0</td>
<td>4.4.0-4.9.0</td>
</tr>
<tr>
<td>3015875</td>
<td>NetQ trace might report incomplete route information when there are multiple default routes in a VRF in the path between the source and destination.</td>
<td>4.1.0-4.4.1</td>
<td>4.5.0-4.9.0</td>
</tr>
<tr>
<td>2896825</td>
<td>WJH monitoring fails to start with netq-agent on Cumulus Linux 5.0. To work around this issue, reinstall the netq-agent package and configure the netq agent to start monitoring:


1. Add the gpg key for the repository:

{{wget -qO - https://apps3.cumulusnetworks.com/setup/cumulus-apps-deb.pubkey | sudo apt-key add -}}


2. Add the repository to {{/etc/apt/sources.list}}:

{{echo 'deb https://apps3.cumulusnetworks.com/repos/deb CumulusLinux-4 netq-latest' | sudo tee -a /etc/apt/sources.list}}


3. Reinstall the netq-agent package:

{{sudo apt-get update &amp;&amp; sudo apt-get install --reinstall netq-agent}}</td>
<td>4.1.0-4.1.1</td>
<td>4.2.0-4.9.0</td>
</tr>
<tr>
<td>2885440</td>
<td>After upgrading to NetQ 4.1.0, validation checks might show intermittent errors that are not valid while the validation application processess pending messages after upgrade. This condition will clear once all messages are processed.</td>
<td>4.1.0-4.1.1</td>
<td>4.2.0-4.9.0</td>
</tr>
<tr>
<td>2843640</td>
<td>In NetQ clustered environments, the network snapshot feature may fail.</td>
<td>4.0.0-4.1.1</td>
<td>4.2.0-4.9.0</td>
</tr>
<tr>
<td>2817749</td>
<td>If you configure an event suppression rule with {{is_active false}}, the event will no longer be displayed with the {{netq show events-config}} command.</td>
<td>4.0.1-4.2.0</td>
<td>4.3.0-4.9.0</td>
</tr>
<tr>
<td>2815596</td>
<td>The NetQ Cloud VM for KVM hypervisors installer and opta-check fail because the minimum disk requirements do not meet the default image settings. To work around this issue, increase the disk space from 32GB to 64GB before you run the {{netq bootstrap}} command.


1. Check the size of the existing hard disk in the VM to confirm it is 32 GB. In this example, the number of 1 MB blocks is 31583, or 32 GB.

	cumulus@netq-401-cloud:~$ df -hm /
	Filesystem     1M-blocks  Used Available Use% Mounted on
	/dev/vda1          31583  1192     30375   4% /

2. Shutdown the VM.

3. Check the size of the existing disk on the server hosting the VM to confirm it is 32 GB. In this example, the size appears in the virtual size field:


	root@server:/var/lib/libvirt/images# qemu-img info netq-4.0.1-ubuntu-18.04-tscloud-qemu.qcow2
	image: netq-4.0.1-ubuntu-18.04-tscloud-qemu.qcow2
	file format: qcow2
	virtual size: 32G (34359738368 bytes)
	disk size: 1.3G
	cluster_size: 65536
	Format specific information:
	    compat: 1.1
	    lazy refcounts: false
	    refcount bits: 16
	    corrupt: false

4. Add 32 GB to the image:

	root@server:/var/lib/libvirt/images# qemu-img resize netq-4.0.1-ubuntu-18.04-tscloud-qemu.qcow2 +32G
	Image resized.

5. Verify the change.

	root@server:/var/lib/libvirt/images# qemu-img info netq-4.0.1-ubuntu-18.04-tscloud-qemu.qcow2
	image: netq-3.1.0-ubuntu-18.04-tscloud-qemu.qcow2
	file format: qcow2
	virtual size: 64G (68719476736 bytes)
	disk size: 1.3G
	cluster_size: 65536
	Format specific information:
	    compat: 1.1
	    lazy refcounts: false
	    refcount bits: 16
	    corrupt: false

6. Start the VM and log back in.

7. Run the following commands on the partition, referencing the filesystem /dev/vda1 obtained in step 1:


	cumulus@netq-401-cloud:~$ sudo growpart /dev/vda 1
	CHANGED: partition=1 start=227328 old: size=66881503 end=67108831 new: size=133990367,end=134217695

	cumulus@netq-401-cloud:~$ sudo resize2fs /dev/vda1
	resize2fs 1.44.1 (24-Mar-2018)
	Filesystem at /dev/vda1 is mounted on /; on-line resizing required
	old_desc_blocks = 4, new_desc_blocks = 8
	The filesystem on /dev/vda1 is now 16748795 (4k) blocks long.

8. Verify the disk is now configured with 64 GB. In this example, the number of 1 MB blocks is now 63341, or 64 GB:

	cumulus@netq-401-cloud:~$ df -hm /
	Filesystem     1M-blocks  Used Available Use% Mounted on
	/dev/vda1          63341  1193     62132   2% /</td>
<td>4.0.1-4.1.1</td>
<td>4.2.0-4.9.0</td>
</tr>
<tr>
<td>2711101</td>
<td>When RoCE (RDMA over Converged Ethernet) data collection is enabled in Cumulus Linux 4.3.z and 4.4.z, you can experience high dual uplink convergence times.
To work around this issue, disable RoCE monitoring:

1. Edit &apos;/etc/netq/commands/cl4-netq-commands.yml&apos; and comment out the following lines:
        #- period: "60"
        #  key: "roce"
        #  isactive: true
        #  command: "/usr/lib/cumulus/mlxcmd --json roce counters"
        #  parser: "local"

2. Delete the &apos;/var/run/netq/netq_commands.yml&apos; file:
        $ sudo rm /var/run/netq/netq_commands.yml

3. Restart the NetQ agent:
       $ netq config agent restart</td>
<td>4.0.0-4.1.1</td>
<td>4.2.0-4.9.0</td>
</tr>
</table>
<table name="Fixed Issues in 4.1.0">
<tr>
<th> Issue ID </th>
<th> Description </th>
<th> Affects </th>
</tr>
<tr>
<td>2893000</td>
<td>CVE-2021-44228: Apache Log4j2 &lt;=2.14.1 JNDI features used in configuration, log messages, and parameters do not protect against attacker controlled LDAP and other JNDI related endpoints.</td>
<td>2.4.0-4.0.1</td>
</tr>
<tr>
<td>2690469</td>
<td>While upgrading an on-premises deployment from version 2.4.x to 3.x.y then to 4.x, the upgrade fails during the NetQ application stage.
To work around this issue, run the following command on the NetQ telemetry server, then start the upgrade again:
&apos;netq install opta activate-job config-key EhVuZXRxLWVuZHBvaW50LWdhdGV3YXkYsagDIiw3T2sweW9kR3Y4Wk9sTHU3MkwrQTRjNkhhQkU3bVpBNVlZVjEvWWgyZGJBPQ==&apos;</td>
<td>3.2.1-4.0.1</td>
</tr>
</table>
</tables>