<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Network Virtualization on Cumulus Networks Documentation</title>
    <link>http://example.org/Cumulus_Linux/Network_Virtualization/</link>
    <description>Recent content in Network Virtualization on Cumulus Networks Documentation</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="http://example.org/Cumulus_Linux/Network_Virtualization/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Ethernet Virtual Private Network - EVPN</title>
      <link>http://example.org/Cumulus_Linux/Network_Virtualization/Ethernet_Virtual_Private_Network_-_EVPN/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://example.org/Cumulus_Linux/Network_Virtualization/Ethernet_Virtual_Private_Network_-_EVPN/</guid>
      <description>VXLAN is the de facto technology for implementing network virtualization in the data center, enabling layer 2 segments to be extended over an IP core (the underlay). The initial definition of VXLAN (RFC 7348) did not include any control plane and relied on a flood-and-learn approach for MAC address learning. An alternate deployment model was to use a controller or a technology such as Lightweight Network Virtualization (LNV) in Cumulus Linux.</description>
    </item>
    
    <item>
      <title>VXLAN Active-Active Mode</title>
      <link>http://example.org/Cumulus_Linux/Network_Virtualization/VXLAN_Active-Active_Mode/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://example.org/Cumulus_Linux/Network_Virtualization/VXLAN_Active-Active_Mode/</guid>
      <description>VXLAN active-active mode allows a pair of MLAG switches to act as a single VTEP, providing active-active VXLAN termination for bare metal as well as virtualized workloads.
There are some differences whether you&amp;rsquo;re deploying this with EVPN or LNV. This chapter outlines the configurations for both options.
Terminology    Term Definition     VTEP The virtual tunnel endpoint. This is an encapsulation and decapsulation point for VXLANs.</description>
    </item>
    
    <item>
      <title>VXLAN Routing</title>
      <link>http://example.org/Cumulus_Linux/Network_Virtualization/VXLAN_Routing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://example.org/Cumulus_Linux/Network_Virtualization/VXLAN_Routing/</guid>
      <description>VXLAN routing, sometimes referred to as inter-VXLAN routing, provides IP routing between VXLAN VNIs in overlay networks. The routing of traffic is based on the inner header or the overlay tenant IP address.
Because VXLAN routing is fundamentally routing, it is most commonly deployed with a control plane, such as Ethernet Virtual Private Network (EVPN). You can set up static routing too, either with or without the Cumulus Lightweight Network Virtualization (LNV) for MAC distribution and BUM handling.</description>
    </item>
    
    <item>
      <title>VXLAN Scale</title>
      <link>http://example.org/Cumulus_Linux/Network_Virtualization/VXLAN_Scale/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://example.org/Cumulus_Linux/Network_Virtualization/VXLAN_Scale/</guid>
      <description>On Broadcom Trident II and Tomahawk switches running Cumulus Linux, there is a limit to the number of VXLANs you can configure simultaneously. The limit most often given is 2000 VXLANs, but you might want to get more specific and know exactly the limit for your specific design.
While this limitation does apply to Trident II+, Trident3, or Maverick ASICs, Cumulus Linux supports the same number of VXLANs on these ASICs as it does for Trident II or Tomahawk ASICs.</description>
    </item>
    
    <item>
      <title>Hybrid Cloud Connectivity with QinQ and VXLANs</title>
      <link>http://example.org/Cumulus_Linux/Network_Virtualization/Hybrid_Cloud_Connectivity_with_QinQ_and_VXLANs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://example.org/Cumulus_Linux/Network_Virtualization/Hybrid_Cloud_Connectivity_with_QinQ_and_VXLANs/</guid>
      <description>QinQ is an amendment to the IEEE 802.1Q specification that provides the capability for multiple VLAN tags to be inserted into a single Ethernet frame.
The primary use case for QinQ with VXLAN is where a service provider who offers multi-tenant layer 2 connectivity between different customersâ€™ data centers (private clouds) may also need to connect those data centers to public cloud providers. Public clouds often has a mandatory QinQ handoff interface, where the outer tag is for the customer and the inner tag is for the service.</description>
    </item>
    
    <item>
      <title>Troubleshooting VXLANs</title>
      <link>http://example.org/Cumulus_Linux/Network_Virtualization/Troubleshooting_VXLANs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://example.org/Cumulus_Linux/Network_Virtualization/Troubleshooting_VXLANs/</guid>
      <description>This topic discusses various ways you can verify and troubleshoot VXLANs.
Verify the Registration Node Daemon Use the vxrdctl vxlans ****command to see the configured VNIs, the local address being used to source the VXLAN tunnel, and the service node being used.
     cumulus@leaf1:~$ vxrdctl vxlans VNI Local Addr Svc Node === ========== ======== 10 10.2.1.1 10.2.1.3 30 10.2.1.1 10.2.1.3 2000 10.2.1.1 10.2.1.3   cumulus@leaf2:~$ vxrdctl vxlans VNI Local Addr Svc Node === ========== ======== 10 10.</description>
    </item>
    
  </channel>
</rss>