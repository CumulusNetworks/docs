<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Network Virtualization on Cumulus Networks Documentation</title>
    <link>docs.cumulusnetworks.com/version/cumulus-linux-343/Network-Virtualization/</link>
    <description>Recent content in Network Virtualization on Cumulus Networks Documentation</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="docs.cumulusnetworks.com/version/cumulus-linux-343/Network-Virtualization/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Integrating with VMware NSX</title>
      <link>docs.cumulusnetworks.com/version/cumulus-linux-343/Network-Virtualization/Integrating-with-VMware-NSX/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>docs.cumulusnetworks.com/version/cumulus-linux-343/Network-Virtualization/Integrating-with-VMware-NSX/</guid>
      <description>Switches running Cumulus Linux can integrate with VMware NSX to act as VTEP gateways. The VMware NSX controller provides consistent provisioning across virtual and physical server infrastructures.
Getting Started Before you integrate VXLANs with NSX, make sure you have the following components:
 A switch (L2 gateway) with a Broadcom Tomahawk, Trident II+ or Trident II chipset, or a Mellanox Spectrum chipset running Cumulus Linux
 OVSDB server (ovsdb-server), included in Cumulus Linux</description>
    </item>
    
    <item>
      <title>Integrating with VMware NSX-V</title>
      <link>docs.cumulusnetworks.com/version/cumulus-linux-343/Network-Virtualization/Integrating-with-VMware-NSX-V/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>docs.cumulusnetworks.com/version/cumulus-linux-343/Network-Virtualization/Integrating-with-VMware-NSX-V/</guid>
      <description>Switches running Cumulus Linux can integrate with VMware NSX-V to act as VTEP gateways. The VMware NSX-V controller provides consistent provisioning across virtual and physical server infrastructures.
Getting Started Before you integrate VXLANs with NSX-V, make sure you have the following components:
 A switch (L2 gateway) with a Broadcom Tomahawk, Trident II+ or Trident II chipset, or a Mellanox Spectrum chipset running Cumulus Linux
 OVSDB server (ovsdb-server), included in Cumulus Linux</description>
    </item>
    
    <item>
      <title>Integrating Hardware VTEPs with Midokura MidoNet and OpenStack</title>
      <link>docs.cumulusnetworks.com/version/cumulus-linux-343/Network-Virtualization/Integrating-Hardware-VTEPs-with-Midokura-MidoNet-and-OpenStack/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>docs.cumulusnetworks.com/version/cumulus-linux-343/Network-Virtualization/Integrating-Hardware-VTEPs-with-Midokura-MidoNet-and-OpenStack/</guid>
      <description>Cumulus Linux seamlessly integrates with the MidoNet OpenStack infrastructure, where the switches provide the VTEP gateway for terminating VXLAN tunnels from within MidoNet. MidoNet connects to the OVSDB server running on the Cumulus Linux switch, and exchanges information about the VTEPs and MAC addresses associated with the OpenStack Neutron networks. This provides seamless Ethernet connectivity between virtual and physical server infrastructures.
Getting Started Before you create VXLANs with MidoNet, make sure you have the following components:</description>
    </item>
    
    <item>
      <title>Static MAC Bindings with VXLAN</title>
      <link>docs.cumulusnetworks.com/version/cumulus-linux-343/Network-Virtualization/Static-MAC-Bindings-with-VXLAN/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>docs.cumulusnetworks.com/version/cumulus-linux-343/Network-Virtualization/Static-MAC-Bindings-with-VXLAN/</guid>
      <description>Cumulus Linux includes native Linux VXLAN kernel support.
Requirements A VXLAN configuration requires a switch with a Broadcom Tomahawk, Trident II+ or Trident II chipset running Cumulus Linux 2.0 or later, or a Mellanox Spectrum chipset running Cumulus Linux 3.2.0 or later.
For a basic VXLAN configuration, you should ensure that:
 The VXLAN has a network identifier (VNI); do not use 0 or 16777215 as the VNI ID, as they are reserved values under Cumulus Linux.</description>
    </item>
    
    <item>
      <title>Ethernet Virtual Private Network - EVPN</title>
      <link>docs.cumulusnetworks.com/version/cumulus-linux-343/Network-Virtualization/Ethernet-Virtual-Private-Network-EVPN/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>docs.cumulusnetworks.com/version/cumulus-linux-343/Network-Virtualization/Ethernet-Virtual-Private-Network-EVPN/</guid>
      <description>Ethernet Virtual Private Network (EVPN) provides a control plane for VXLANs in Cumulus Linux, with the following functionality:
 VNI membership exchange between VTEPs using EVPN type-3 (Inclusive multicast Ethernet tag) routes.
 Exchange of host MAC and IP addresses using EVPN type-2 (MAC/IP advertisement) routes.
 Support for host/VM mobility (MAC and IP moves) through exchange of the MAC Mobility Extended community.
 Support for dual-attached hosts via VXLAN active-active mode; note that MAC synchronization between the peer switches is done using MLAG.</description>
    </item>
    
    <item>
      <title>VXLAN Routing</title>
      <link>docs.cumulusnetworks.com/version/cumulus-linux-343/Network-Virtualization/VXLAN-Routing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>docs.cumulusnetworks.com/version/cumulus-linux-343/Network-Virtualization/VXLAN-Routing/</guid>
      <description>VXLAN routing, sometimes referred to as inter-VXLAN routing, provides IP routing between VXLAN VNIs in overlay networks. The routing of traffic is based on the inner header or the overlay tenant IP address.
VXLAN routing is supported on the following platforms:
 Broadcom Tomahawk using an internal loopback on one or more switch ports
 Broadcom Trident II+ using a RIOT profile
 Mellanox Spectrum
  If you want to use VXLAN routing on a Trident II switch, you must use a hyperloop.</description>
    </item>
    
    <item>
      <title>VXLAN Scale</title>
      <link>docs.cumulusnetworks.com/version/cumulus-linux-343/Network-Virtualization/VXLAN-Scale/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>docs.cumulusnetworks.com/version/cumulus-linux-343/Network-Virtualization/VXLAN-Scale/</guid>
      <description>On Broadcom Trident II and Tomahawk hardware running Cumulus Linux, there is a limit on the amount of VXLANs you can configure simultaneously. The limit most often given is 2000 VXLANs that can be run, but network architects want to get more specific and know exactly the limit for their specific design.
The limit is a Physical to Virtual mappings where we can hold 15,000 mappings in hardware before we hit hash collisions.</description>
    </item>
    
    <item>
      <title>VXLAN Hyperloop</title>
      <link>docs.cumulusnetworks.com/version/cumulus-linux-343/Network-Virtualization/VXLAN-Hyperloop/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>docs.cumulusnetworks.com/version/cumulus-linux-343/Network-Virtualization/VXLAN-Hyperloop/</guid>
      <description>This chapter covers configuring VXLAN gateways using a loopback cable (which we call a hyperloop) on non-RIOT (VXLAN routing) capable ASICs running Cumulus Linux.
The Broadcom Trident II and Tomahawk ASICs have a limitation where a layer 2 bridge that contains a VXLAN interface can not also have an IP address assigned to it. This is an expected limitation with this ASIC, because of the ordering of the decapsulation. A packet that is decapsulated will already have passed the portion of the ASIC capable of reading the IP address lookup (for example, VXLAN lookup happens before IP address lookup).</description>
    </item>
    
    <item>
      <title>Static VXLAN Tunnels</title>
      <link>docs.cumulusnetworks.com/version/cumulus-linux-343/Network-Virtualization/Static-VXLAN-Tunnels/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>docs.cumulusnetworks.com/version/cumulus-linux-343/Network-Virtualization/Static-VXLAN-Tunnels/</guid>
      <description>In VXLAN-based networks, there are a range of complexities and challenges in determining the destination virtual tunnel endpoints (VTEPs) for any given VXLAN. At scale, various solutions, including Lightweight Network Virtualization (LNV), controller-based options like Midokura MidoNet or VMware NSX and even new standards like EVPN are attempts to address these complexities, however do retain their own complexities.
Enter static VXLAN tunnels, which simply serve to connect two VTEPs in a given environment.</description>
    </item>
    
    <item>
      <title>Hybrid Cloud Connectivity with QinQ and VXLANs</title>
      <link>docs.cumulusnetworks.com/version/cumulus-linux-343/Network-Virtualization/Hybrid-Cloud-Connectivity-with-QinQ-and-VXLANs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>docs.cumulusnetworks.com/version/cumulus-linux-343/Network-Virtualization/Hybrid-Cloud-Connectivity-with-QinQ-and-VXLANs/</guid>
      <description>QinQ is an amendment to the IEEE 802.1Q specification that provides the capability for multiple VLAN tags to be inserted into a single Ethernet frame.
The primary use case for QinQ with VXLAN is where a service provider who offers multi-tenant layer 2 connectivity between different customersâ€™ data centers (private clouds) may also need to connect those data centers to public cloud providers. Public clouds often has a mandatory QinQ handoff interface, where the outer tag is for the customer and the inner tag is for the service.</description>
    </item>
    
  </channel>
</rss>